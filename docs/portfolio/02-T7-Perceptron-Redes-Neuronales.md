---
title: "De Perceptr√≥n a Redes Neuronales"
date: 2025-10-05
---

# De Perceptr√≥n a Redes Neuronales

## Contexto
En esta pr√°ctica se explor√≥ la evoluci√≥n de los modelos de aprendizaje supervisado desde el **perceptr√≥n simple** hasta las **redes neuronales multicapa (MLP)**, analizando tanto sus fundamentos te√≥ricos como su implementaci√≥n pr√°ctica en distintos frameworks: *scikit-learn*, *TensorFlow* y *PyTorch Lightning*.  

El objetivo fue comprender c√≥mo el aumento de capas y funciones de activaci√≥n permite resolver problemas no linealmente separables (como XOR) y c√≥mo los frameworks modernos ofrecen distintos niveles de control, automatizaci√≥n y flexibilidad.

## Objetivos
- Implementar y analizar el comportamiento del perceptr√≥n simple (AND, OR, NOT, XOR).  
- Entrenar una red neuronal multicapa (MLP) para resolver XOR.  
- Comparar implementaciones en *scikit-learn*, *TensorFlow* y *PyTorch Lightning*.  
- Analizar funciones de activaci√≥n, p√©rdida, batch size, epochs y convergencia.  
- Reflexionar sobre buenas pr√°cticas, reproducibilidad y elecci√≥n de frameworks seg√∫n contexto.

## Actividades (con tiempos estimados)

| Actividad                             | Tiempo | Resultado esperado                                   |
|--------------------------------------|:------:|------------------------------------------------------|
| Implementaci√≥n del perceptr√≥n (AND, OR, NOT) | 30m   | Red neuronal lineal que resuelve operaciones simples |
| Exploraci√≥n del caso XOR             | 30m   | Demostraci√≥n de no linealidad y necesidad de MLP     |
| Entrenamiento de MLP con sklearn     | 40m   | Modelo funcional que resuelve XOR correctamente      |
| Red neuronal en TensorFlow/Keras     | 45m   | Implementaci√≥n controlada con funciones de activaci√≥n|
| Experimentos con PyTorch Lightning   | 45m   | Entrenamiento modular, reproducible y limpio         |
| Reflexi√≥n y conexi√≥n entre frameworks| 30m   | Comparaci√≥n t√©cnica y conceptual                     |

## Desarrollo
**Parte 1: Perceptr√≥n simple (AND, OR, NOT, XOR)**  
- Los modelos AND, OR y NOT fueron correctamente resueltos, al ser **linealmente separables**.  
- El modelo XOR no fue posible con un solo perceptr√≥n, confirmando su **no linealidad**.  
- Se introdujo el concepto de **frontera de decisi√≥n lineal** y su limitaci√≥n en el plano 2D.

### Decision Boundary: Perceptr√≥n vs MLP

![Frontera de decisi√≥n - Perceptr√≥n vs MLP](../assets/boundary_perceptron.png){ width="700" }

!!! note "Interpretaci√≥n"
    A la izquierda, el perceptr√≥n simple traza una frontera lineal incapaz de separar XOR.  
    A la derecha, el MLP crea una frontera **no lineal (curva)** que combina m√∫ltiples neuronas, resolviendo el problema.


**Parte 2: MLP con scikit-learn**  
- Se entren√≥ un **MLPClassifier** con una capa oculta y funci√≥n de activaci√≥n *relu*.  
- Se visualiz√≥ la **superficie de decisi√≥n** y se verific√≥ que el modelo logra separar correctamente el patr√≥n XOR.  
- Se discuti√≥ la diferencia entre una red simple y una red profunda.

**Parte 3: TensorFlow y PyTorch Lightning**  
- En TensorFlow/Keras se construy√≥ una red neuronal desde cero, configurando:
  - Capas ocultas, optimizador, epochs y batch size.  
  - Curvas de *loss* y *val_loss* para detectar overfitting.  
- En PyTorch Lightning se implement√≥ el mismo modelo de manera **modular y reproducible**, utilizando par√°metros como `deterministic=True` para garantizar consistencia.  

## Curvas de entrenamiento en TensorFlow
![Curvas de perdida y precision](../assets/curvas_de_entrenamiento.png) {width="720"}
!!! note "Analisis"
    Las curvas de entrenamiento muestran que:
    - La p√©rdida de entrenamiento (**Training Loss**) disminuye progresivamente, se√±al de aprendizaje.
    - La p√©rdida de validaci√≥n (**Validation Loss**) se estabiliza, indicando que el modelo generaliza bien.
    - La precisi√≥n de entrenamiento y validaci√≥n convergen sobre el 90%, sin se√±ales de sobreajuste.

- En **PyTorch Lightning**, se implement√≥ el mismo modelo de forma modular y reproducible, utilizando `deterministic=True` para asegurar resultados consistentes y separando las fases de entrenamiento y evaluaci√≥n con `training_step` y `test_step`.  

### Comparaci√≥n de Matrices de Confusi√≥n entre Frameworks

![Matrices de confusi√≥n - Sklearn, TensorFlow y PyTorch](../assets/UT2-TA7-Matrices_de_Confusion.png){ width="780" }

!!! tip "Interpretaci√≥n"
    Las tres implementaciones presentan resultados equivalentes con ligeras variaciones:
    - La **diagonal principal** (valores en azul oscuro) representa las predicciones correctas.  
    - Las diferencias m√≠nimas entre frameworks se deben a la inicializaci√≥n aleatoria y al optimizador utilizado.  
    - Todos los modelos logran una **alta precisi√≥n y consistencia**, validando la efectividad del enfoque multicapa.

**Comparaci√≥n de frameworks:**  

| Escenario | Framework ideal | Justificaci√≥n |
|------------|----------------|----------------|
| ‚ö° Prototipo r√°pido | `sklearn MLP` | Entrenamiento autom√°tico y simple |
| üè≠ Producci√≥n | `TensorFlow / Keras` | Control de arquitectura, GPU y despliegue |
| üî¨ Investigaci√≥n | `PyTorch Lightning` | Flexibilidad y limpieza de c√≥digo |

## Evidencias
- Entrenamiento del perceptr√≥n simple (AND, OR, NOT).  
- Ejemplo de XOR no lineal y visualizaci√≥n de la frontera fallida.  
- Superficie de decisi√≥n del MLP resolviendo XOR.  
- Curvas de aprendizaje (loss vs val_loss) en TensorFlow.  
- Comparaci√≥n de frameworks y funciones de activaci√≥n.

### Superficie de decisi√≥n del MLP
[![Visualizaci√≥n del MLP resolviendo XOR](../assets/mlp_xor_surface.png){ width="280" }](../assets/mlp_xor_surface.png)

```python linenums="1"
# Ejemplo: MLP para resolver XOR en sklearn
from sklearn.neural_network import MLPClassifier
import numpy as np

X = np.array([[0,0],[0,1],[1,0],[1,1]])
y = np.array([0,1,1,0])

mlp = MLPClassifier(hidden_layer_sizes=(2,), activation='relu', max_iter=5000, random_state=42)
mlp.fit(X, y)
```

print("Predicciones:", mlp.predict(X))

!!! note "Resultados"
El modelo logr√≥ predecir correctamente los cuatro casos del XOR, demostrando que una capa oculta y una funci√≥n de activaci√≥n no lineal bastan para resolver el problema.

???+ info "Conexiones con otras unidades"
- Con Titanic (Unidad 1): ambos aplican clasificaci√≥n supervisada y an√°lisis de variables predictoras.
- Con Regresi√≥n Log√≠stica (Unidad 2): se profundiza en funciones de activaci√≥n y entrenamiento por lotes.
- Con Validaci√≥n de Modelos (Unidad 3): se retoma la importancia de reproducibilidad y estabilidad.

## Evidencias

Esta pr√°ctica permiti√≥ comprender c√≥mo una simple modificaci√≥n en la arquitectura (a√±adir una capa oculta) cambia la capacidad de representaci√≥n del modelo.
Tambi√©n reforz√≥ la diferencia entre frameworks: scikit-learn como herramienta r√°pida de prototipado, TensorFlow para control avanzado y PyTorch Lightning para investigaci√≥n reproducible.

Aprend√≠ que la elecci√≥n del framework depende del prop√≥sito: velocidad, control o escalabilidad.
La pr√°ctica integr√≥ conceptos de las unidades previas y foment√≥ una visi√≥n completa del flujo de aprendizaje autom√°tico.

## Checklist
- [x] Implementaci√≥n de perceptr√≥n simple 
- [x] An√°lisis de XOR y necesidad de no linealidad
- [x] MLP con sklearn y visualizaci√≥n de resultados  
- [x] Red neuronal con TensorFlow
- [x] Entrenamiento modular con PyTorch Lightning
