---
title: "Del perceptr√≥n al aprendizaje profundo: c√≥mo las redes neuronales aprendieron a resolver XOR"
date: 2025-10-05
---

# Del perceptr√≥n al aprendizaje profundo: c√≥mo las redes neuronales aprendieron a resolver XOR

## Contexto
En esta pr√°ctica se explor√≥ la evoluci√≥n de los modelos de aprendizaje supervisado desde el **perceptr√≥n simple** hasta las **redes neuronales multicapa (MLP)**, analizando tanto sus fundamentos te√≥ricos como su implementaci√≥n pr√°ctica en distintos frameworks: *scikit-learn*, *TensorFlow* y *PyTorch Lightning*.  

El objetivo fue comprender c√≥mo el aumento de capas y funciones de activaci√≥n permite resolver problemas no linealmente separables (como XOR) y c√≥mo los frameworks modernos ofrecen distintos niveles de control, automatizaci√≥n y flexibilidad.

## Objetivos
- Implementar y analizar el comportamiento del perceptr√≥n simple (AND, OR, NOT, XOR).  
- Entrenar una red neuronal multicapa (MLP) para resolver XOR.  
- Comparar implementaciones en *scikit-learn*, *TensorFlow* y *PyTorch Lightning*.  
- Analizar funciones de activaci√≥n, p√©rdida, batch size, epochs y convergencia.  
- Reflexionar sobre buenas pr√°cticas, reproducibilidad y elecci√≥n de frameworks seg√∫n contexto.

## Actividades (con tiempos estimados)

| Actividad                             | Tiempo | Resultado esperado                                   |
|--------------------------------------|:------:|------------------------------------------------------|
| Implementaci√≥n del perceptr√≥n (AND, OR, NOT) | 30m   | Red neuronal lineal que resuelve operaciones simples |
| Exploraci√≥n del caso XOR             | 30m   | Demostraci√≥n de no linealidad y necesidad de MLP     |
| Entrenamiento de MLP con sklearn     | 40m   | Modelo funcional que resuelve XOR correctamente      |
| Red neuronal en TensorFlow/Keras     | 45m   | Implementaci√≥n controlada con funciones de activaci√≥n|
| Experimentos con PyTorch Lightning   | 45m   | Entrenamiento modular, reproducible y limpio         |
| Reflexi√≥n y conexi√≥n entre frameworks| 30m   | Comparaci√≥n t√©cnica y conceptual                     |

---

## Desarrollo

### Parte 1: Perceptr√≥n simple (AND, OR, NOT, XOR)
- Los modelos **AND**, **OR** y **NOT** fueron correctamente resueltos, al ser **linealmente separables**.  
- El modelo **XOR** no fue posible con un solo perceptr√≥n, confirmando su **no linealidad**.  
- Se introdujo el concepto de **frontera de decisi√≥n lineal** y su limitaci√≥n en el plano 2D.

#### Frontera de decisi√≥n: Perceptr√≥n vs MLP

![Frontera de decisi√≥n - Perceptr√≥n vs MLP](../assets/boundary_perceptron.png){ width="700" }

!!! note "Interpretaci√≥n"
    A la izquierda, el perceptr√≥n simple traza una frontera lineal incapaz de separar XOR.  
    A la derecha, el MLP crea una frontera **no lineal (curva)** que combina m√∫ltiples neuronas, resolviendo el problema.

---

### Parte 2: MLP con *scikit-learn*
- Se entren√≥ un **MLPClassifier** con una capa oculta y funci√≥n de activaci√≥n *ReLU*.  
- Se verific√≥ que el modelo logra separar correctamente el patr√≥n XOR.  
- Se discuti√≥ la diferencia entre una red simple (una capa oculta) y una red profunda (m√∫ltiples capas).

```python linenums="1"
from sklearn.neural_network import MLPClassifier
import numpy as np

X = np.array([[0,0],[0,1],[1,0],[1,1]])
y = np.array([0,1,1,0])

mlp = MLPClassifier(hidden_layer_sizes=(2,), activation='relu', max_iter=5000, random_state=42)
mlp.fit(X, y)
print("Predicciones:", mlp.predict(X))
```


**Parte 3: TensorFlow y PyTorch Lightning**  
- En TensorFlow/Keras se construy√≥ una red neuronal desde cero, configurando:
  - Capas ocultas, optimizador, epochs y batch size.  
  - Curvas de *loss* y *val_loss* para detectar overfitting.  
- En PyTorch Lightning se implement√≥ el mismo modelo de manera **modular y reproducible**, utilizando par√°metros como `deterministic=True` para garantizar consistencia.  

## Curvas de entrenamiento en TensorFlow
![Curvas de perdida y precision](../assets/curvas_de_entrenamiento.png) {width="720"}

!!! note "Analisis"
    Las curvas de entrenamiento muestran que:
    - La p√©rdida de entrenamiento (**Training Loss**) disminuye progresivamente, se√±al de aprendizaje.
    - La p√©rdida de validaci√≥n (**Validation Loss**) se estabiliza, indicando que el modelo generaliza bien.
    - La precisi√≥n de entrenamiento y validaci√≥n convergen sobre el 90%, sin se√±ales de sobreajuste.

- En **PyTorch Lightning**, se implement√≥ el mismo modelo de forma modular y reproducible, utilizando `deterministic=True` para asegurar resultados consistentes y separando las fases de entrenamiento y evaluaci√≥n con `training_step` y `test_step`.  

### Comparaci√≥n de Matrices de Confusi√≥n entre Frameworks

![Matrices de confusi√≥n - Sklearn, TensorFlow y PyTorch](../assets/UT2-TA7-Matrices_de_Confusion.png){ width="780" }

!!! tip "Interpretaci√≥n"
    Las tres implementaciones presentan resultados equivalentes con ligeras variaciones:
    - La **diagonal principal** (valores en azul oscuro) representa las predicciones correctas.  
    - Las diferencias m√≠nimas entre frameworks se deben a la inicializaci√≥n aleatoria y al optimizador utilizado.  
    - Todos los modelos logran una **alta precisi√≥n y consistencia**, validando la efectividad del enfoque multicapa.

**Comparaci√≥n de frameworks:**  

| Escenario | Framework ideal | Justificaci√≥n |
|------------|----------------|----------------|
| ‚ö° Prototipo r√°pido | `sklearn MLP` | Entrenamiento autom√°tico y simple |
| üè≠ Producci√≥n | `TensorFlow / Keras` | Control de arquitectura, GPU y despliegue |
| üî¨ Investigaci√≥n | `PyTorch Lightning` | Flexibilidad y limpieza de c√≥digo |

### Reflexi√≥n
Esta pr√°ctica permiti√≥ comprender c√≥mo una simple modificaci√≥n en la arquitectura (a√±adir una capa oculta) cambia la capacidad de representaci√≥n del modelo.
Tambi√©n reforz√≥ la diferencia entre frameworks:

- scikit-learn como herramienta r√°pida de prototipado.

- TensorFlow para control avanzado.

- PyTorch Lightning para investigaci√≥n reproducible.

Aprend√≠ que la elecci√≥n del framework depende del prop√≥sito: velocidad, control o escalabilidad.
La pr√°ctica integr√≥ conceptos de unidades previas y consolid√≥ una visi√≥n completa del flujo de aprendizaje autom√°tico.


## Checklist
- [x] Implementaci√≥n de perceptr√≥n simple 
- [x] An√°lisis de XOR y necesidad de no linealidad
- [x] MLP con sklearn y visualizaci√≥n de resultados  
- [x] Red neuronal con TensorFlow
- [x] Entrenamiento modular con PyTorch Lightning
- [x] Comparaci√≥n de frameworks
- [x] Reflexi√≥n integradora entre unidades
